{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:05.272820Z",
     "start_time": "2025-10-06T17:18:05.268345Z"
    }
   },
   "source": [
    "# --- Step 1: Import Libraries --- #\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:06.061385Z",
     "start_time": "2025-10-06T17:18:05.287959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 2: Load and Merge Data --- #\n",
    "# Make sure the paths are correct for your project structure\n",
    "try:\n",
    "    df_train = pd.read_csv('../datasets/train.csv', low_memory=False)\n",
    "    df_store = pd.read_csv('../datasets/store.csv', low_memory=False)\n",
    "    print(\"Files loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.csv' and 'store.csv' are in your datasets folder.\")\n",
    "    exit()\n",
    "\n",
    "df = pd.merge(df_train, df_store, how='left', on='Store')\n",
    "print(\"Datasets merged successfully.\")"
   ],
   "id": "8360f6b580942705",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n",
      "Datasets merged successfully.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:06.488957Z",
     "start_time": "2025-10-06T17:18:06.072859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 3: Initial Cleaning & Filtering (Lessons from EDA) --- #\n",
    "# Filter out days when stores were closed, as sales are always 0.\n",
    "df = df[df['Open'] == 1].copy()\n",
    "# We no longer need the 'Open' column as it's now always 1.\n",
    "df = df.drop('Open', axis=1)\n",
    "\n",
    "# Convert the 'Date' column to a proper datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(\"Initial cleaning and filtering complete.\")"
   ],
   "id": "3d62cde769fb12c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cleaning and filtering complete.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:07.141790Z",
     "start_time": "2025-10-06T17:18:06.505901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 4: Feature Engineering --- #\n",
    "print(\"Performing feature engineering on the Date column...\")\n",
    "# Extract time-based features from the 'Date' column\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek # Monday=0, Sunday=6\n",
    "\n",
    "# We no longer need the original 'Date' column\n",
    "df = df.drop('Date', axis=1)\n",
    "\n",
    "# Handle the 'StateHoliday' column which has mixed types (0 and '0')\n",
    "df['StateHoliday'] = df['StateHoliday'].replace({0: '0'})\n",
    "\n",
    "# Convert other categorical columns into numbers using One-Hot Encoding\n",
    "categorical_features = ['StoreType', 'Assortment', 'StateHoliday']\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "print(\"Feature engineering complete.\")"
   ],
   "id": "88f1e8a5307b8589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature engineering on the Date column...\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:09.610399Z",
     "start_time": "2025-10-06T17:18:07.183714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 5: Final Data Preparation for Modeling --- #\n",
    "# Define our target (y) and initial features (X)\n",
    "y = df['Sales']\n",
    "# We drop columns that are either results, IDs, or too complex for this model\n",
    "X = df.drop(['Sales', 'Customers', 'Store', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], axis=1)\n",
    "\n",
    "# One-Hot Encode all remaining text columns\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Impute missing 'CompetitionDistance' values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "# Convert back to DataFrame\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "692f190f3950c04a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T17:18:53.903193Z",
     "start_time": "2025-10-06T17:18:09.684336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 6: Train and Evaluate the Model --- #\n",
    "print(\"\\n--- Training the Random Forest Regressor (This may take a few minutes)... ---\")\n",
    "\n",
    "# Create and train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_features=0.5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- Model training complete. Evaluating... ---\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"\\n--- Final Model Evaluation ---\")\n",
    "print(f\"Mean Absolute Error (MAE): €{mae:,.2f}\")"
   ],
   "id": "48cfa7d628b2752e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the Random Forest Regressor (This may take a few minutes)... ---\n",
      "--- Model training complete. Evaluating... ---\n",
      "\n",
      "--- Final Model Evaluation ---\n",
      "Mean Absolute Error (MAE): €789.71\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
