{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:04.660778Z",
     "start_time": "2025-11-05T00:28:03.562298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 1: Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb  # Import the XGBoost library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "id": "19852fa582eca800",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:04.943922Z",
     "start_time": "2025-11-05T00:28:04.664772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 2: Load and Merge Data ---\n",
    "# Make sure the paths are correct for your project structure\n",
    "try:\n",
    "    df_train = pd.read_csv('../datasets/train.csv', low_memory=False, parse_dates=['Date'])\n",
    "    df_store = pd.read_csv('../datasets/store.csv', low_memory=False)\n",
    "    print(\"Files loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.csv' and 'store.csv' are in your datasets folder.\")\n",
    "    exit()\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(df_train, df_store, how='left', on='Store')\n",
    "print(\"Datasets merged successfully.\")"
   ],
   "id": "7cdf48d294859ea9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n",
      "Datasets merged successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:05.429951Z",
     "start_time": "2025-11-05T00:28:04.998164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 3: Full Data Preparation (Our \"Champion\" Pipeline) ---\n",
    "print(\"Preparing all features...\")\n",
    "\n",
    "# 1. Filter out days when stores were closed\n",
    "df = df[df['Open'] == 1].copy()\n",
    "df = df.drop('Open', axis=1)\n",
    "\n",
    "# 2. Rename columns\n",
    "df = df.rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "\n",
    "# 3. Engineer Date Features\n",
    "df['Year'] = df['ds'].dt.year\n",
    "df['Month'] = df['ds'].dt.month\n",
    "df['Day'] = df['ds'].dt.day\n",
    "df['DayOfWeek'] = df['ds'].dt.dayofweek\n",
    "\n",
    "# 4. Handle 'StateHoliday'\n",
    "df['StateHoliday'] = df['StateHoliday'].replace({0: '0'})\n",
    "\n",
    "# 5. One-Hot Encode Categorical Features\n",
    "categorical_features = ['StoreType', 'Assortment', 'StateHoliday']\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 6. Fill Missing Values\n",
    "cols_to_impute = ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "\n",
    "# 7. Drop unnecessary columns\n",
    "df = df.drop(['Customers', 'Store', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], axis=1, errors='ignore')\n",
    "\n",
    "print(\"Data preparation and feature engineering complete.\")"
   ],
   "id": "6141574db86daa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing all features...\n",
      "Data preparation and feature engineering complete.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:05.485513Z",
     "start_time": "2025-11-05T00:28:05.439192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 4: Split Data into Train and Test Sets ---\n",
    "# We'll use the last 6 weeks as our test set (a standard time series split)\n",
    "cutoff_date = df['ds'].max() - pd.to_timedelta('42 days')\n",
    "df_train = df[df['ds'] <= cutoff_date].copy()\n",
    "df_test = df[df['ds'] > cutoff_date].copy()\n",
    "\n",
    "# Prepare X and y, dropping the date column\n",
    "y_train = df_train['y']\n",
    "X_train = df_train.drop(['ds', 'y'], axis=1)\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(['ds', 'y'], axis=1)\n",
    "\n",
    "# Align columns to ensure test set matches train set\n",
    "train_cols = X_train.columns\n",
    "X_test = X_test.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} records\")\n",
    "print(f\"Testing set:  {X_test.shape[0]} records\")"
   ],
   "id": "af1f863b8cc8b80d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 804110 records\n",
      "Testing set:  40282 records\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:05.692310Z",
     "start_time": "2025-11-05T00:28:05.497449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 5: Scale the Features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data scaling complete.\")"
   ],
   "id": "60303870c666e150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaling complete.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:21.970597Z",
     "start_time": "2025-11-05T00:28:05.704133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 6: The Showdown - Train and Evaluate Both Models ---\n",
    "\n",
    "# --- Model 1: Random Forest (Our Champion) ---\n",
    "print(\"\\n--- Training Random Forest Champion ---\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_features=0.5)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "\n",
    "print(f\"Random Forest MAE: €{rf_mae:,.2f}\")\n",
    "\n",
    "# --- Model 2: XGBoost (The Challenger) ---\n",
    "print(\"\\n--- Training XGBoost Challenger ---\")\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror')\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test_scaled)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "\n",
    "print(f\"XGBoost MAE:       €{xgb_mae:,.2f}\")"
   ],
   "id": "d81360abd7b93fa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Random Forest Champion ---\n",
      "Random Forest MAE: €798.54\n",
      "\n",
      "--- Training XGBoost Challenger ---\n",
      "XGBoost MAE:       €1,036.54\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:28:21.978235Z",
     "start_time": "2025-11-05T00:28:21.976073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 7: The Final Verdict ---\n",
    "print(\"\\n--- The Showdown: Final Results ---\")\n",
    "print(f\"Random Forest MAE: €{rf_mae:,.2f}\")\n",
    "print(f\"XGBoost MAE:       €{xgb_mae:,.2f}\")\n",
    "\n",
    "if xgb_mae < rf_mae:\n",
    "    print(\"\\nWE HAVE A NEW CHAMPION! XGBoost wins!\")\n",
    "else:\n",
    "    print(\"\\nThe reigning champion, Random Forest, holds its ground!\")"
   ],
   "id": "3e93cc2ed47fcf8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- The Showdown: Final Results ---\n",
      "Random Forest MAE: €798.54\n",
      "XGBoost MAE:       €1,036.54\n",
      "\n",
      "The reigning champion, Random Forest, holds its ground!\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
