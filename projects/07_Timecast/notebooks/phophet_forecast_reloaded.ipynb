{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T03:55:13.420371Z",
     "start_time": "2025-11-04T03:55:13.414928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 1: Import Libraries --- #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from prophet import Prophet\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "id": "435fa49e790dddda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T03:55:13.786893Z",
     "start_time": "2025-11-04T03:55:13.448393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 2: Load and Merge Data ---\n",
    "# Make sure the paths are correct for your project structure\n",
    "try:\n",
    "    df_train = pd.read_csv('../datasets/train.csv', low_memory=False, parse_dates=['Date'])\n",
    "    df_store = pd.read_csv('../datasets/store.csv', low_memory=False)\n",
    "    print(\"Files loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train.csv' and 'store.csv' are in your datasets folder.\")\n",
    "    exit()\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(df_train, df_store, how='left', on='Store')\n",
    "print(\"Datasets merged successfully.\")"
   ],
   "id": "bda28174ed3f9deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n",
      "Datasets merged successfully.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T03:55:14.154040Z",
     "start_time": "2025-11-04T03:55:13.805763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 3: Full Data Preparation (for both models) ---\n",
    "print(\"Preparing data...\")\n",
    "# 1. Filter out days when stores were closed\n",
    "df = df[df['Open'] == 1].copy()\n",
    "df = df.drop('Open', axis=1)\n",
    "\n",
    "# 2. Rename columns for Prophet\n",
    "df = df.rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "\n",
    "# 3. Engineer Date Features\n",
    "df['Year'] = df['ds'].dt.year\n",
    "df['Month'] = df['ds'].dt.month\n",
    "df['Day'] = df['ds'].dt.day\n",
    "df['DayOfWeek'] = df['ds'].dt.dayofweek\n",
    "\n",
    "# 4. Handle 'StateHoliday'\n",
    "df['StateHoliday'] = df['StateHoliday'].replace({0: '0'})\n",
    "\n",
    "# 5. One-Hot Encode Categorical Features\n",
    "categorical_features = ['StoreType', 'Assortment', 'StateHoliday']\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 6. Fill Missing Values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['CompetitionDistance'] = imputer.fit_transform(df[['CompetitionDistance']])\n",
    "\n",
    "# 7. Drop unnecessary columns\n",
    "df = df.drop(['Customers', 'Store', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], axis=1)\n",
    "\n",
    "print(\"Data preparation and feature engineering complete.\")"
   ],
   "id": "8b45c2f400d2540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data preparation and feature engineering complete.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T03:55:14.202583Z",
     "start_time": "2025-11-04T03:55:14.166950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 4: Split Data into Train and Test Sets ---\n",
    "# For time series, we must split by date. We'll use the last 6 weeks as our test set.\n",
    "cutoff_date = df['ds'].max() - pd.to_timedelta('42 days')\n",
    "df_train = df[df['ds'] <= cutoff_date].copy()\n",
    "df_test = df[df['ds'] > cutoff_date].copy()\n",
    "\n",
    "print(f\"Training set: {df_train.shape[0]} records\")\n",
    "print(f\"Testing set:  {df_test.shape[0]} records\")"
   ],
   "id": "dc5ceccbff500248",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 804110 records\n",
      "Testing set:  40282 records\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T03:55:14.436431Z",
     "start_time": "2025-11-04T03:55:14.215095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 5: Engineer and Clean All Features (The \"Regressors\") ---\n",
    "print(\"Performing feature engineering...\")\n",
    "# Extract time-based features\n",
    "df['Year'] = df['ds'].dt.year\n",
    "df['Month'] = df['ds'].dt.month\n",
    "df['Day'] = df['ds'].dt.day\n",
    "df['DayOfWeek'] = df['ds'].dt.dayofweek\n",
    "\n",
    "# Handle the 'StateHoliday' column (convert 0 to '0')\n",
    "df['StateHoliday'] = df['StateHoliday'].replace({0: '0'})\n",
    "\n",
    "# One-Hot Encode all categorical features\n",
    "categorical_features = ['StoreType', 'Assortment', 'StateHoliday']\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# *** THIS IS THE FIX ***\n",
    "# Handle ALL known missing numerical columns\n",
    "cols_to_impute = ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "# *** END OF FIX ***\n",
    "\n",
    "# Drop columns we won't use\n",
    "df = df.drop(['Customers', 'Store', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], axis=1)\n",
    "print(\"Feature engineering and missing value handling complete.\")"
   ],
   "id": "1a9df878fe4ce223",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature engineering...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'StateHoliday'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'StateHoliday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mDayOfWeek\u001B[39m\u001B[33m'\u001B[39m] = df[\u001B[33m'\u001B[39m\u001B[33mds\u001B[39m\u001B[33m'\u001B[39m].dt.dayofweek\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Handle the 'StateHoliday' column (convert 0 to '0')\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m df[\u001B[33m'\u001B[39m\u001B[33mStateHoliday\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mStateHoliday\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m.replace({\u001B[32m0\u001B[39m: \u001B[33m'\u001B[39m\u001B[33m0\u001B[39m\u001B[33m'\u001B[39m})\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# One-Hot Encode all categorical features\u001B[39;00m\n\u001B[32m     13\u001B[39m categorical_features = [\u001B[33m'\u001B[39m\u001B[33mStoreType\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mAssortment\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mStateHoliday\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4105\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4106\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4107\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4108\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4109\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'StateHoliday'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Step 6: Split Data into Train and Test Sets ---\n",
    "cutoff_date = df['ds'].max() - pd.to_timedelta('42 days')\n",
    "df_train = df[df['ds'] <= cutoff_date].copy()\n",
    "df_test = df[df['ds'] > cutoff_date].copy()\n",
    "\n",
    "print(f\"Training set: {df_train.shape[0]} records\")\n",
    "print(f\"Testing set:  {df_test.shape[0]} records\")"
   ],
   "id": "81c14e4cccbfabc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Step 7: The Rematch - Prophet vs. Random Forest ---\n",
    "\n",
    "# --- Model 1: Random Forest (Our Champion) ---\n",
    "print(\"\\n--- Training Random Forest Champion ---\")\n",
    "y_train_rf = df_train['y']\n",
    "X_train_rf = df_train.drop(['ds', 'y'], axis=1)\n",
    "y_test_rf = df_test['y']\n",
    "X_test_rf = df_test.drop(['ds', 'y'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_rf_scaled = scaler.fit_transform(X_train_rf)\n",
    "X_test_rf_scaled = scaler.transform(X_test_rf)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_features=0.5)\n",
    "rf_model.fit(X_train_rf_scaled, y_train_rf)\n",
    "rf_predictions = rf_model.predict(X_test_rf_scaled)\n",
    "rf_mae = mean_absolute_error(y_test_rf, rf_predictions)\n",
    "\n",
    "print(f\"Random Forest MAE: €{rf_mae:,.2f}\")\n",
    "\n",
    "# --- Model 2: Prophet with Extra Regressors (The Challenger) ---\n",
    "print(\"\\n--- Training Prophet Challenger (This may take a few minutes)... ---\")\n",
    "regressor_names = list(df_train.drop(columns=['ds', 'y']).columns)\n",
    "\n",
    "prophet_model_adv = Prophet(daily_seasonality=False)\n",
    "\n",
    "for regressor in regressor_names:\n",
    "    prophet_model_adv.add_regressor(regressor)\n",
    "\n",
    "# Train the model\n",
    "prophet_model_adv.fit(df_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "prophet_predictions_adv = prophet_model_adv.predict(df_test)\n",
    "prophet_mae_adv = mean_absolute_error(df_test['y'], prophet_predictions_adv['yhat'])\n",
    "\n",
    "print(f\"Advanced Prophet MAE: €{prophet_mae_adv:,.2f}\")\n",
    "\n",
    "# --- Step 8: The Final Verdict ---\n",
    "print(\"\\n--- The Rematch: Final Results ---\")\n",
    "print(f\"Random Forest MAE:     €{rf_mae:,.2f}\")\n",
    "print(f\"Advanced Prophet MAE:  €{prophet_mae_adv:,.2f}\")\n",
    "\n",
    "if prophet_mae_adv < rf_mae:\n",
    "    print(\"\\nNew Champion! The tuned Prophet model wins!\")\n",
    "else:\n",
    "    print(\"\\nThe reigning champion, Random Forest, holds its ground!\")"
   ],
   "id": "b958af1517748cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
