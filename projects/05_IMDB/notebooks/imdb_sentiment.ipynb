{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:50.602874Z",
     "start_time": "2025-08-27T01:28:47.674159Z"
    }
   },
   "source": [
    "# --- Step 0: Import Libraries --- #\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:50.886129Z",
     "start_time": "2025-08-27T01:28:50.610982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 1: Load the Dataset --- #\n",
    "print(\"Loading the IMDB dataset...\")\n",
    "file_path = '../datasets/IMDB Dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Dataset loaded successfully.\")"
   ],
   "id": "42fad1bf9a58e171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the IMDB dataset...\n",
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:51.777280Z",
     "start_time": "2025-08-27T01:28:50.943424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 2: Text Cleaning Function --- #\n",
    "# We create a function to handle all our text cleaning steps in one place.\n",
    "def clean_text(text):\n",
    "    # 1. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 2. Remove non-alphabetic characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    # 3. Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "print(\"Applying text cleaning...\")\n",
    "# Apply the cleaning function to all reviews\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "print(\"Text cleaning complete.\")\n"
   ],
   "id": "888fe84835bcd54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying text cleaning...\n",
      "Text cleaning complete.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:51.790577Z",
     "start_time": "2025-08-27T01:28:51.788693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 3: Define Features (X) and Target (y) --- #\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n"
   ],
   "id": "3d8baf3918346683",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:51.803568Z",
     "start_time": "2025-08-27T01:28:51.799106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 4: Split the Data --- #\n",
    "# We split our data into a training set and a testing set.\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split complete.\")"
   ],
   "id": "b3eb540a37239315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Data split complete.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:54.167391Z",
     "start_time": "2025-08-27T01:28:51.817419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 5: Vectorization using TF-IDF --- #\n",
    "print(\"Vectorizing text data...\")\n",
    "# Create the TF-IDF Vectorizer\n",
    "# We'll also remove common English \"stop words\" (like 'the', 'a', 'in')\n",
    "# and only consider words that appear in at least 5 reviews (min_df=5).\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "\n",
    "# Fit the vectorizer on the TRAINING data and transform it\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the TEST data using the SAME fitted vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(\"Vectorization complete.\")"
   ],
   "id": "2d2619fcf579036c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text data...\n",
      "Vectorization complete.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:54.431517Z",
     "start_time": "2025-08-27T01:28:54.177900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 6: Train the Logistic Regression Model --- #\n",
    "print(\"Training the sentiment analysis model...\")\n",
    "# Logistic Regression is a great, fast baseline model for text classification.\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Model training complete.\")"
   ],
   "id": "5826cf5796dcd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the sentiment analysis model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardopolaco/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: divide by zero encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/Users/eduardopolaco/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: overflow encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/Users/eduardopolaco/PycharmProjects/Blog-AI-Projects/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: invalid value encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:54.480540Z",
     "start_time": "2025-08-27T01:28:54.440365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 7: Evaluate the Model --- #\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "# Make predictions on the unseen test data\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ],
   "id": "f4344e861fbac3bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Model Accuracy: 89.22%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      4961\n",
      "    positive       0.88      0.91      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T01:28:54.492020Z",
     "start_time": "2025-08-27T01:28:54.488052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Step 8: Test with a New, Custom Review --- #\n",
    "print(\"\\n--- Testing with a new review ---\")\n",
    "new_review_positive = \"This was an amazing and brilliant film. I loved every minute of it!\"\n",
    "new_review_negative = \"What a complete waste of time. The acting was terrible and the plot was boring.\"\n",
    "\n",
    "# Clean and vectorize the new reviews\n",
    "cleaned_positive = clean_text(new_review_positive)\n",
    "vectorized_positive = vectorizer.transform([cleaned_positive])\n",
    "\n",
    "cleaned_negative = clean_text(new_review_negative)\n",
    "vectorized_negative = vectorizer.transform([cleaned_negative])\n",
    "\n",
    "# Make predictions\n",
    "prediction_pos = model.predict(vectorized_positive)\n",
    "prediction_neg = model.predict(vectorized_negative)\n",
    "\n",
    "print(f\"Review: '{new_review_positive}'\")\n",
    "print(f\"Predicted Sentiment: {prediction_pos[0]}\\n\")\n",
    "\n",
    "print(f\"Review: '{new_review_negative}'\")\n",
    "print(f\"Predicted Sentiment: {prediction_neg[0]}\")"
   ],
   "id": "59dd975d238d29e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with a new review ---\n",
      "Review: 'This was an amazing and brilliant film. I loved every minute of it!'\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Review: 'What a complete waste of time. The acting was terrible and the plot was boring.'\n",
      "Predicted Sentiment: negative\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e14dba12d6dcbfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
